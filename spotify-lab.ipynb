{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify Login - For One Hour\n",
    "After running this click Sign-In and login to Spotify. If the Time expires then repeat the process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyauth import ParamsSpotify, Auth\n",
    "\n",
    "auth = Auth(ParamsSpotify(redirect_uri='http://localhost:8888/callback', client_id=\"9e4657eefbac41afa98c61f590d8fd51\"))\n",
    "auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Stuff and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Image\n",
    "from pandas.io.json import json_normalize\n",
    "from pandas import DataFrame,read_pickle,merge\n",
    "from pandas import DataFrame as df\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger()\n",
    "#logger.setLevel(logging.INFO)\n",
    "\n",
    "def fetch( path, url=None ):\n",
    "    callPath = url if (url!=None) else (\"https://api.spotify.com\" + path)\n",
    "    response = requests.get(callPath , headers= {\"Authorization\":\"Bearer \" + auth.access_token })\n",
    "    if (response.status_code!=200):\n",
    "        logging.debug(\"error \")\n",
    "    return response.json()\n",
    "\n",
    "def post( path, body, url=None ):\n",
    "    callPath = url if (url!=None) else (\"https://api.spotify.com\" + path)\n",
    "    response = requests.post(callPath, headers= {\"Authorization\":\"Bearer \" + auth.access_token }, data=json.dumps(body))\n",
    "    if (response.status_code!=200):\n",
    "        logging.debug(\"error \")\n",
    "    return response.json()\n",
    "\n",
    "def delete2( path, body, url=None ):\n",
    "    callPath = url if (url!=None) else (\"https://api.spotify.com\" + path)\n",
    "    response = requests.delete(callPath, headers= {\"Authorization\":\"Bearer \" + auth.access_token }, data=json.dumps(body))\n",
    "    if (response.status_code!=200):\n",
    "        logging.debug(\"error \")\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def fetchPage( path, offset, limit):\n",
    "    res = fetch(  path + \"?offset=\" + str(offset) + \"&limit=\" + str(limit))\n",
    "    return res\n",
    "\n",
    "def fetchAll( path ):\n",
    "    more = fetchPage( path, 0, 50)\n",
    "    limit = more[\"limit\"]\n",
    "    total = more[\"total\"] - limit\n",
    "    items = more[\"items\"]\n",
    "    while((total>0) and (more[\"next\"]!=None )):\n",
    "        more = fetch( None, url = more[\"next\"] )\n",
    "        items.extend( more[\"items\"])\n",
    "        total = total - len(more[\"items\"])\n",
    "    return items\n",
    "\n",
    "def fetchPageIds( path, ids): \n",
    "    return fetch(\"{0}?ids={1}\".format(path,\",\".join(ids)))\n",
    "\n",
    "def fetchAllIds( path, resultField, ids, pageSize=50, existingDf=None):\n",
    "    if (existingDf is not None):\n",
    "        keys = existingDf.index.values\n",
    "        ids = list(filter( lambda id: (id not in keys),ids))\n",
    "        existingDf = existingDf.reset_index()\n",
    "        logging.info(\"Filtering out {0} IDs. Now {1}\".format(len(keys), len(ids)))\n",
    "    total = len(ids)\n",
    "    logging.info(\"Requesting {0} rows. {1} ... {2}\".format(total, path, resultField))\n",
    "    offset = 0\n",
    "    while (offset < total) :\n",
    "        result = fetchPageIds(path, ids[offset: min(total, offset + pageSize)])\n",
    "        if (resultField not in result ):\n",
    "            logger.error(\"Key not in results: {0}\".format( result.keys() ))\n",
    "            raise Exception(\"Cannot find key in results\")\n",
    "        items = json_normalize(result[resultField])\n",
    "        if (existingDf is None):\n",
    "            logging.info(\"Creating new DF {0}\".format(len(items)))\n",
    "            existingDf = items\n",
    "        else:\n",
    "            existingDf = existingDf.append(items, ignore_index=True )\n",
    "        offset += len(items)\n",
    "    return existingDf.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "def addTracks(playlistId, tracks):\n",
    "    return post(\"/v1/users/{0}/playlists/{1}/tracks\".format(userId,playlistId), {\n",
    "        \"uris\": tracks\n",
    "    })\n",
    "\n",
    "def createPlaylist(name,description):\n",
    "    return post(\"/v1/users/{0}/playlists\".format(userId), {\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"public\": True\n",
    "    })\n",
    "\n",
    "def fetchPlaylists():\n",
    "    return fetchAll(\"/v1/me/playlists\")\n",
    "\n",
    "def fetchPlaylistTracks( playlistId ):\n",
    "    return fetchAll(\"/v1/playlists/{0}/tracks\".format(playlistId))\n",
    "\n",
    "\n",
    "def reconcilePlaylistTracks( playlistName, description, tracks ) :\n",
    "    existingPlaylists = list(fetchPlaylists())\n",
    "    existingPlaylist = list(filter(lambda playlist: playlist[\"name\"]==playlistName,existingPlaylists))\n",
    "    playlist = existingPlaylist[0] if (len(existingPlaylist)>0) else createPlaylist( name = playlistName, description = description )\n",
    "    existing = json_normalize(fetchPlaylistTracks( playlist[\"id\"] ), sep=\"_\")\n",
    "    if (existing.empty):\n",
    "        return addTracks( playlist[\"id\"], tracks )\n",
    "    existingUris = existing[\"track_uri\"].values.tolist()\n",
    "    urisDel = list(filter( lambda e: e not in tracks, existingUris))\n",
    "    urisAdd = list(filter( lambda t: t not in existingUris, tracks))\n",
    "    while (len(urisDel)>0):\n",
    "        page = urisDel[-100:]\n",
    "        bodylist = list(map( lambda x: dict([('uri',x)]), page ))\n",
    "        url = \"/v1/playlists/{0}/tracks\".format(str(playlist[\"id\"]))\n",
    "        delete2(url, { \"tracks\": bodylist })\n",
    "        urisDel = urisDel[:-100]\n",
    "    while (len(urisAdd)>0):\n",
    "        page = urisAdd[-100:]\n",
    "        addTracks(playlist[\"id\"],page)\n",
    "        urisAdd = urisAdd[:-100]\n",
    "        \n",
    "user = fetch(\"/v1/me\")\n",
    "userId = user[\"id\"]\n",
    "Image(url=user[\"images\"][0][\"url\"], width=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read The User Library\n",
    "This process may take a little while. The library tracks are cached locally, so this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetchAll(\"/v1/me/tracks\")\n",
    "tracksDf = json_normalize(data, sep=\"_\").set_index(\"track_uri\")\n",
    "tracksDf.to_pickle(\"mytracks.pkl\")\n",
    "tracksDf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the library cache exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracksDf = read_pickle(\"mytracks.pkl\")\n",
    "tracksCache = tracksDf[[\"added_at\",\"track_name\",\"track_album_name\",\"track_album_id\"]]\n",
    "tracksCache.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Artists\n",
    "Load the artists one by one. Use the Pickle File **artists.pkl** as a cache.\n",
    "* Create a DataFrame using the cache file if one exists (otherwise None)\n",
    "* Get the list of all unique artist_ids from the previous DF\n",
    "* Call `fetchAllIds` - using the artists path, the `artists` JSON field path and the cache DF\n",
    "* Recreate the new artistDf (Dict returned)\n",
    "* Save the file back to **artists.pkl**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Track to Artist Table\n",
    "Pick out the track.artists array for each library track record. The meta (parent record) is the track.id. Use a prefix for both the meta and the record because they both use id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistsPickle = read_pickle(\"artists.pkl\") if (os.path.isfile(\"artists.pkl\")) else None \n",
    "artistIds = list(set(artist_and_track[\"artist_id\"].values))\n",
    "artists = fetchAllIds(\"/v1/artists\",\"artists\",artistIds,existingDf=artistsPickle)\n",
    "artistsDf = json_normalize(artists).set_index(\"id\")\n",
    "artistsDf.to_pickle(\"artists.pkl\")\n",
    "\n",
    "artist_and_track = json_normalize( data=data, record_path=['track','artists'],  meta=[[\"track\",\"name\"],[\"track\",\"uri\"]],  record_prefix='artist_',   sep=\"_\" )\n",
    "artist_and_track = artist_and_track[['track_name','artist_id','artist_name', 'track_uri']]\n",
    "\n",
    "artistsDf[[\"name\",\"genres\"]].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albumsPickle = read_pickle(\"albums.pkl\") if (os.path.isfile(\"albums.pkl\")) else None \n",
    "album_ids  = list(set(tracksDf[\"track_album_id\"].values))\n",
    "albums = fetchAllIds(\"/v1/albums\",\"albums\",album_ids,pageSize=20,existingDf=albumsPickle)\n",
    "albumsDf = json_normalize(albums, sep=\"_\").set_index(\"id\")\n",
    "albumsDf.to_pickle(\"albums.pkl\")\n",
    "\n",
    "albumsDf[\"released\"] = albumsDf.apply(lambda al: datetime.strptime(al[\"release_date\"], \"%Y\" if (al.release_date_precision==\"year\") else \"%Y-%m\" if (al.release_date_precision==\"month\") else \"%Y-%m-%d\"), axis=1) \n",
    "\n",
    "libraryWithAlbums = merge(tracksDf,albumsDf, left_on=\"track_album_id\", right_index=True, suffixes=(\"_track\",\"_album\"))\n",
    "libraryWithAlbums[[\"name\",\"release_date\",\"tracks.total\",\"released\"]].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Features in Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresPickle = read_pickle(\"features.pkl\") if (os.path.isfile(\"features.pkl\")) else None \n",
    "features = fetchAllIds(\"/v1/audio-features\",\"audio_features\",tracksDf[\"track_id\"].values,pageSize=50,existingDf=featuresPickle)\n",
    "featuresDf = json_normalize(features, sep=\"_\").set_index(\"uri\")\n",
    "featuresDf.to_pickle(\"features.pkl\")\n",
    "libraryWithFeatures = merge(libraryWithAlbums,featuresDf, left_index=True, right_index=True, how=\"outer\")\n",
    "libraryWithFeatures[[\"track_name\",\"tempo\",\"loudness\",\"energy\",\"released\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "## All Read - let's create an auto playlist\n",
    "\n",
    "\n",
    "\n",
    "### Running Playlist \n",
    "* Tempo between 160 and 200 (for cadence)\n",
    "* Energy above 0.6\n",
    "* Danceability above 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPlaylist = libraryWithFeatures[ \n",
    "#        (libraryWithFeatures.tempo>155) \n",
    "#                                  & (libraryWithFeatures.tempo<170) \n",
    "#                                  & (libraryWithFeatures.released>(datetime.now()+timedelta(days=-36500))) \n",
    "                                  (libraryWithFeatures.energy>0.8 )\n",
    "                                  & (libraryWithFeatures.loudness>-9 )\n",
    "                                 & (libraryWithFeatures.danceability>0.8 )]\n",
    "reconcilePlaylistTracks(\"Auto Run Fast\",\"Tempo>150 < 190 energy>50\",newPlaylist.index.values.tolist())\n",
    "newPlaylist[[\"track_name\",\"released\",\"tempo\",\"track_artists\",\"energy\",\"loudness\",\"tempo\",\"danceability\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
